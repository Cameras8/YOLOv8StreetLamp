#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
è·¯ç¯çŠ¶æ€æ£€æµ‹Webåº”ç”¨
ä½¿ç”¨Streamlitåˆ›å»ºä¸€ä¸ªç®€å•çš„Webç•Œé¢ï¼Œç”¨äºå±•ç¤ºè·¯ç¯æ£€æµ‹æ¨¡å‹çš„é¢„æµ‹ç»“æœ
"""

import os
import time
from pathlib import Path

import cv2
import numpy as np
import streamlit as st
from PIL import Image
from ultralytics import YOLO


def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®é¡µé¢æ ‡é¢˜å’Œå›¾æ ‡
    st.set_page_config(
        page_title="è·¯ç¯çŠ¶æ€æ£€æµ‹ç³»ç»Ÿ",
        page_icon="ğŸ’¡",
        layout="wide"
    )
    
    # é¡µé¢æ ‡é¢˜
    st.title("ğŸ’¡ è·¯ç¯çŠ¶æ€æ£€æµ‹ç³»ç»Ÿ")
    st.markdown("åŸºäºYOLOv8çš„è·¯ç¯çŠ¶æ€æ£€æµ‹ç³»ç»Ÿï¼Œå¯ä»¥è¯†åˆ«è·¯ç¯åŠå…¶å·¥ä½œçŠ¶æ€ï¼ˆäº®/ä¸äº®/ä¸å¤Ÿäº®ï¼‰")
    
    # ä¾§è¾¹æ é…ç½®
    st.sidebar.header("æ¨¡å‹é…ç½®")
    
    # æ¨¡å‹é€‰æ‹©
    model_path = st.sidebar.selectbox(
        "é€‰æ‹©æ¨¡å‹",
        options=["runs/detect/train10/weights/best.pt", "runs/detect/train10/weights/last.pt"],
        index=0
    )
    
    # ç½®ä¿¡åº¦é˜ˆå€¼
    conf_threshold = st.sidebar.slider(
        "ç½®ä¿¡åº¦é˜ˆå€¼",
        min_value=0.1,
        max_value=1.0,
        value=0.3,
        step=0.05
    )
    
    # æ–‡ä»¶ä¸Šä¼ 
    st.sidebar.header("è¾“å…¥")
    source_option = st.sidebar.radio(
        "é€‰æ‹©è¾“å…¥æº",
        options=["ä¸Šä¼ å›¾ç‰‡", "ä¸Šä¼ è§†é¢‘", "æ‘„åƒå¤´"],
        index=0
    )
    
    # åŠ è½½æ¨¡å‹
    @st.cache_resource
    def load_model(model_path):
        return YOLO(model_path)
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(model_path):
        st.error(f"é”™è¯¯ï¼šæ¨¡å‹æ–‡ä»¶ {model_path} ä¸å­˜åœ¨!")
        return
    
    # åŠ è½½æ¨¡å‹
    with st.spinner("åŠ è½½æ¨¡å‹ä¸­..."):
        model = load_model(model_path)
    
    # ç±»åˆ«åç§°
    class_names = ["StreetLamp", "Obscured"]
    
    # å¤„ç†ä¸Šä¼ çš„å›¾ç‰‡
    if source_option == "ä¸Šä¼ å›¾ç‰‡":
        uploaded_file = st.sidebar.file_uploader("ä¸Šä¼ å›¾ç‰‡", type=["jpg", "jpeg", "png"])
        
        if uploaded_file is not None:
            # è½¬æ¢ä¸Šä¼ çš„æ–‡ä»¶ä¸ºOpenCVæ ¼å¼
            file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
            image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # æ˜¾ç¤ºåŸå§‹å›¾åƒ
            col1, col2 = st.columns(2)
            with col1:
                st.subheader("åŸå§‹å›¾åƒ")
                st.image(image_rgb, use_column_width=True)
            
            # è¿›è¡Œé¢„æµ‹
            with st.spinner("æ­£åœ¨æ£€æµ‹..."):
                results = model.predict(
                    source=image,
                    conf=conf_threshold,
                    verbose=False
                )
                
                result = results[0]
                
                # è·å–æ£€æµ‹æ¡†
                boxes = result.boxes
                
                # ç»Ÿè®¡ç»“æœ
                total_lamps = 0
                obscured_lamps = 0
                
                # åœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœ
                result_img = image.copy()
                
                for box in boxes:
                    # è·å–ç±»åˆ«IDå’Œç½®ä¿¡åº¦
                    cls_id = int(box.cls.item())
                    conf = box.conf.item()
                    
                    # è·å–è¾¹ç•Œæ¡†åæ ‡
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    
                    # ç¡®å®šé¢œè‰²å’Œæ ‡ç­¾
                    if cls_id == 0:  # StreetLamp
                        color = (0, 255, 0)  # ç»¿è‰²
                        label = f"StreetLamp {conf:.2f}"
                        total_lamps += 1
                    else:  # Obscured
                        color = (0, 0, 255)  # çº¢è‰²
                        label = f"Obscured {conf:.2f}"
                        obscured_lamps += 1
                        total_lamps += 1
                    
                    # ç»˜åˆ¶è¾¹ç•Œæ¡†
                    cv2.rectangle(result_img, (x1, y1), (x2, y2), color, 2)
                    
                    # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
                    text_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]
                    cv2.rectangle(result_img, (x1, y1 - text_size[1] - 5), (x1 + text_size[0], y1), color, -1)
                    
                    # ç»˜åˆ¶æ ‡ç­¾æ–‡å­—
                    cv2.putText(result_img, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
                
                # è½¬æ¢ä¸ºRGBæ ¼å¼ç”¨äºæ˜¾ç¤º
                result_img_rgb = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)
                
                # æ˜¾ç¤ºç»“æœå›¾åƒ
                with col2:
                    st.subheader("æ£€æµ‹ç»“æœ")
                    st.image(result_img_rgb, use_column_width=True)
                
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                st.subheader("æ£€æµ‹ç»Ÿè®¡")
                st.write(f"- æ£€æµ‹åˆ° **{total_lamps}** ä¸ªè·¯ç¯")
                st.write(f"- å…¶ä¸­ **{obscured_lamps}** ä¸ªä¸äº®æˆ–ä¸å¤Ÿäº®")
                st.write(f"- è·¯ç¯æ­£å¸¸å·¥ä½œç‡: **{(total_lamps - obscured_lamps) / total_lamps * 100:.1f}%**" if total_lamps > 0 else "- æœªæ£€æµ‹åˆ°è·¯ç¯")
    
    # å¤„ç†ä¸Šä¼ çš„è§†é¢‘
    elif source_option == "ä¸Šä¼ è§†é¢‘":
        uploaded_file = st.sidebar.file_uploader("ä¸Šä¼ è§†é¢‘", type=["mp4", "avi", "mov"])
        
        if uploaded_file is not None:
            # ä¿å­˜ä¸Šä¼ çš„è§†é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
            temp_file = f"temp_video_{int(time.time())}.mp4"
            with open(temp_file, "wb") as f:
                f.write(uploaded_file.getbuffer())
            
            # æ˜¾ç¤ºè§†é¢‘
            st.subheader("ä¸Šä¼ çš„è§†é¢‘")
            st.video(temp_file)
            
            # å¤„ç†è§†é¢‘æŒ‰é’®
            if st.button("å¼€å§‹æ£€æµ‹"):
                with st.spinner("æ­£åœ¨å¤„ç†è§†é¢‘..."):
                    # è¿›è¡Œé¢„æµ‹
                    results = model.predict(
                        source=temp_file,
                        conf=conf_threshold,
                        save=True,
                        project="results",
                        name="video_result",
                        exist_ok=True
                    )
                    
                    # æ˜¾ç¤ºå¤„ç†åçš„è§†é¢‘
                    output_path = os.path.join("results", "video_result", Path(temp_file).name)
                    if os.path.exists(output_path):
                        st.subheader("æ£€æµ‹ç»“æœ")
                        st.video(output_path)
                    else:
                        st.error("å¤„ç†è§†é¢‘æ—¶å‡ºé”™ï¼Œæœªèƒ½ç”Ÿæˆç»“æœè§†é¢‘")
            
            # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_file):
                os.remove(temp_file)
    
    # å¤„ç†æ‘„åƒå¤´è¾“å…¥
    else:
        st.sidebar.warning("æ³¨æ„ï¼šæ‘„åƒå¤´åŠŸèƒ½åœ¨æŸäº›æµè§ˆå™¨ä¸­å¯èƒ½ä¸å¯ç”¨")
        
        if st.sidebar.button("å¼€å§‹æ‘„åƒå¤´æ£€æµ‹"):
            st.subheader("æ‘„åƒå¤´æ£€æµ‹")
            
            # åˆ›å»ºå ä½ç¬¦
            stframe = st.empty()
            
            # æ‰“å¼€æ‘„åƒå¤´
            cap = cv2.VideoCapture(0)
            
            # æ£€æŸ¥æ‘„åƒå¤´æ˜¯å¦æˆåŠŸæ‰“å¼€
            if not cap.isOpened():
                st.error("æ— æ³•æ‰“å¼€æ‘„åƒå¤´!")
                return
            
            stop_button = st.button("åœæ­¢æ£€æµ‹")
            
            while not stop_button:
                # è¯»å–ä¸€å¸§
                ret, frame = cap.read()
                
                if not ret:
                    st.error("æ— æ³•è¯»å–æ‘„åƒå¤´ç”»é¢!")
                    break
                
                # è¿›è¡Œé¢„æµ‹
                results = model.predict(
                    source=frame,
                    conf=conf_threshold,
                    verbose=False
                )
                
                result = results[0]
                
                # è·å–æ£€æµ‹æ¡†
                boxes = result.boxes
                
                # ç»Ÿè®¡ç»“æœ
                total_lamps = 0
                obscured_lamps = 0
                
                # åœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœ
                result_img = frame.copy()
                
                for box in boxes:
                    # è·å–ç±»åˆ«IDå’Œç½®ä¿¡åº¦
                    cls_id = int(box.cls.item())
                    conf = box.conf.item()
                    
                    # è·å–è¾¹ç•Œæ¡†åæ ‡
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    
                    # ç¡®å®šé¢œè‰²å’Œæ ‡ç­¾
                    if cls_id == 0:  # StreetLamp
                        color = (0, 255, 0)  # ç»¿è‰²
                        label = f"StreetLamp {conf:.2f}"
                        total_lamps += 1
                    else:  # Obscured
                        color = (0, 0, 255)  # çº¢è‰²
                        label = f"Obscured {conf:.2f}"
                        obscured_lamps += 1
                        total_lamps += 1
                    
                    # ç»˜åˆ¶è¾¹ç•Œæ¡†
                    cv2.rectangle(result_img, (x1, y1), (x2, y2), color, 2)
                    
                    # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
                    text_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]
                    cv2.rectangle(result_img, (x1, y1 - text_size[1] - 5), (x1 + text_size[0], y1), color, -1)
                    
                    # ç»˜åˆ¶æ ‡ç­¾æ–‡å­—
                    cv2.putText(result_img, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
                
                # åœ¨ç”»é¢ä¸Šæ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                info_text = f"è·¯ç¯: {total_lamps}, ä¸äº®: {obscured_lamps}"
                cv2.putText(result_img, info_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 165, 255), 2)
                
                # è½¬æ¢ä¸ºRGBæ ¼å¼ç”¨äºæ˜¾ç¤º
                result_img_rgb = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)
                
                # æ›´æ–°æ˜¾ç¤º
                stframe.image(result_img_rgb, channels="RGB")
                
                # æ£€æŸ¥æ˜¯å¦ç‚¹å‡»äº†åœæ­¢æŒ‰é’®
                if stop_button:
                    break
                
                # æ·»åŠ çŸ­æš‚å»¶è¿Ÿ
                time.sleep(0.01)
            
            # é‡Šæ”¾æ‘„åƒå¤´
            cap.release()
    
    # é¡µè„š
    st.markdown("---")
    st.markdown("ğŸ’¡ **è·¯ç¯çŠ¶æ€æ£€æµ‹ç³»ç»Ÿ** | åŸºäºYOLOv8 | 2024")


if __name__ == "__main__":
    main() 